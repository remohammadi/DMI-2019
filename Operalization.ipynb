{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "mention_finder = re.compile(r'@\\w+ ?')\n",
    "symbols_finder = re.compile(r'[^\\w]')\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    if text.startswith('rt '):\n",
    "        text = text[3:]\n",
    "    text = mention_finder.sub('', text)\n",
    "    text = symbols_finder.sub(' ', text)\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text.strip()\n",
    "_test_normalize_text = normalize_text('RT @xyz_ @opl Haha! Hoho!')\n",
    "if _test_normalize_text != 'haha hoho':\n",
    "    raise Exception(\"Not implemented correctly? '{0}'\".format(_test_normalize_text))\n",
    "\n",
    "DATASET_DATE = datetime(2018, 9, 1)\n",
    "\n",
    "# Load the Media Bias/Fact Check db\n",
    "with open(join('data', 'sources.json')) as infile:\n",
    "    sources = json.load(infile)\n",
    "\n",
    "FACTUAL_HALF = set(['MIXED'])\n",
    "FACTUAL_COMPLETELY = set(['HIGH', 'VERY HIGH'])\n",
    "DOMAIN_ALIASES = {\n",
    "    'presstv.ir': 'presstv.com',\n",
    "    'politi.co': 'politico.com',\n",
    "}\n",
    "\n",
    "# A failed attemp to write a function to decode the reported_location field\n",
    "# import pycountry\n",
    "# _countries_cache = {}\n",
    "# def get_country(name):\n",
    "#     c = _countries_cache.get(name, None)\n",
    "#     if name not in _countries_cache:\n",
    "#         c = pycountry.countries.get(name=name)\n",
    "#         if not c and len(name) == 2:\n",
    "#             c = pycountry.countries.get(alpha_2=name.upper())\n",
    "#         if not c and len(name) == 3:\n",
    "#             c = pycountry.countries.get(alpha_3=name.upper())\n",
    "#         if not c:\n",
    "#             c = pycountry.countries.get(official_name=name)\n",
    "#         _countries_cache[name] = c\n",
    "#         if not c:\n",
    "#             print(\"failed to find country for \" + name)\n",
    "#     return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1122936 tweets from 770 users\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "with open(join(\"data\",\"iranian_users.csv\")) as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    users = {row[2]: {'row': row, 'tweets': [], 'scores': None} for row in csvreader if row[0] != 'userid'}\n",
    "\n",
    "tweet_texts = {}\n",
    "repeated_texts = {}\n",
    "repeaters_among_self_tweets = {}\n",
    "repeaters_among_all_tweets = {}\n",
    "    \n",
    "tweet_counter = 0\n",
    "missing_users = set([])\n",
    "with open(join(\"data\",\"iranian_tweets.csv\")) as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    for tweet in csvreader:\n",
    "        screen_name = tweet[3]\n",
    "        if screen_name not in users:\n",
    "            missing_users.add(screen_name)\n",
    "        else:\n",
    "            users[screen_name]['tweets'].append(tweet)\n",
    "            tweet_counter += 1\n",
    "\n",
    "        t = normalize_text(tweet[12])\n",
    "        if len(t) < 5:\n",
    "            continue\n",
    "        if t not in tweet_texts:\n",
    "            tweet_texts[t] = {screen_name: 1, '__total__': 1}\n",
    "        elif screen_name not in tweet_texts[t]:\n",
    "            tweet_texts[t][screen_name] = 1\n",
    "            tweet_texts[t]['__total__'] += 1\n",
    "        else:\n",
    "            tweet_texts[t][screen_name] += 1\n",
    "            tweet_texts[t]['__total__'] += 1\n",
    "\n",
    "        if tweet_texts[t][screen_name] > 2:\n",
    "            if screen_name not in repeaters_among_self_tweets:\n",
    "                repeaters_among_self_tweets[screen_name] = 1\n",
    "            else:\n",
    "                repeaters_among_self_tweets[screen_name] += 1\n",
    "\n",
    "        if tweet_texts[t]['__total__'] > 4:\n",
    "            repeated_texts[t] = tweet_texts[t]['__total__']\n",
    "            if screen_name not in repeaters_among_all_tweets:\n",
    "                repeaters_among_all_tweets[screen_name] = 1\n",
    "            else:\n",
    "                repeaters_among_all_tweets[screen_name] += 1\n",
    "\n",
    "missing_users.remove('user_screen_name')\n",
    "if missing_users:\n",
    "    print(\"Missing users with tweets: \" + ', '.join(list(not_in_sources)))\n",
    "    print()\n",
    "\n",
    "print(\"Loaded {tn} tweets from {un} users\".format(tn=tweet_counter, un=len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated texts:\n",
      "10025 ce qu ils ne vous diront jamais sur noel http  t co qsgh5j9rxt\n",
      "{'marialuis91': 10025, '__total__': 10025}\n",
      " 9232 ce qu ils ne vous diront jamais sur noel http  t co w563d4cdji\n",
      "{'a51115862ba4725c846e77683e9c71d1b1eb246100ca394f1b915f9c7909099d': 9232, '__total__': 9232}\n",
      " 2274 ce qu ils ne vous diront jamais sur noel http  t co jpxd3bawcm\n",
      "{'marialuis91': 2274, '__total__': 2274}\n",
      " 2073 coupe du monde  l image que les cam√©ras n ont pas voulu voir http  t co nztgbyg5mr\n",
      "{'marialuis91': 2073, '__total__': 2073}\n",
      " 2022 united states a structurally racist society http  t co ykqfm3kyjc\n",
      "{'a51115862ba4725c846e77683e9c71d1b1eb246100ca394f1b915f9c7909099d': 2022, '__total__': 2022}\n",
      " 1987 charlie hebdo les bourdes bizarres faites par les terroristes http  t co aviaibnj29\n",
      "{'a51115862ba4725c846e77683e9c71d1b1eb246100ca394f1b915f9c7909099d': 1987, '__total__': 1987}\n",
      " 1790 charlie hebdo les bourdes bizarres faites par les terroristes http  t co rnidkwbngn\n",
      "{'marialuis91': 1790, '__total__': 1790}\n",
      " 1376 ce qu ils ne vous diront jamais sur noel http  t co e0urnp7hil\n",
      "{'a51115862ba4725c846e77683e9c71d1b1eb246100ca394f1b915f9c7909099d': 1376, '__total__': 1376}\n",
      " 1246 fbi  isis recruits young american ladies for sex jihad http  t co bae2k89in0\n",
      "{'marialuis91': 1246, '__total__': 1246}\n",
      " 1102 ferguson s inferno sets the nation amp the state on fire http  t co czamhboih8\n",
      "{'marialuis91': 1102, '__total__': 1102}\n",
      "\n",
      "repeaters_among_self_tweets_max=5.411058801028159\n",
      "repeaters_among_all_tweets_max=5.404346144102511\n"
     ]
    }
   ],
   "source": [
    "from math import log10\n",
    "\n",
    "repeated_texts_sorted = sorted([(v, k) for k, v in repeated_texts.items()], key=lambda x:x[0], reverse=True)\n",
    "print(\"Repeated texts:\")\n",
    "for i in range(min(10, len(repeated_texts_sorted))):\n",
    "    print(\"{n:5} {s}\".format(n=repeated_texts_sorted[i][0], s=repeated_texts_sorted[i][1]))\n",
    "    print(tweet_texts[repeated_texts_sorted[i][1]])\n",
    "\n",
    "repeaters_among_self_tweets_max = log10(max(repeaters_among_self_tweets.values()))\n",
    "repeaters_among_all_tweets_max = log10(max(repeaters_among_all_tweets.values()))\n",
    "\n",
    "print()\n",
    "print(\"repeaters_among_self_tweets_max={0}\".format(repeaters_among_self_tweets_max))\n",
    "print(\"repeaters_among_all_tweets_max={0}\".format(repeaters_among_all_tweets_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Scores for each User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Dimensions:\n",
      "    creation? account age?,\n",
      "    language_score,\n",
      "    working_time_score,\n",
      "    linked_to_domains_score,\n",
      "    repetition_among_self_tweets,\n",
      "    repetition_among_all_tweets,\n",
      "    has_burst,\n",
      "\n",
      "57e2082d64baa89d:   1.87 = (0.3, 1.0, 0.5, 0.0, 0.0, 0.1, 0.0)\n",
      "11891c406c088fdd:   2.19 = (1.0, 0.1, 1.0, 0.0, 0.1, 0.1, 0.0)\n",
      "5ddbd530097789a4:   1.80 = (0.3, 0.2, 0.4, 0.2, 0.1, 0.6, 0.0)\n",
      "50012d5e4f959a3d:   2.10 = (0.6, 0.2, 0.5, 0.7, 0.0, 0.1, 0.0)\n",
      "28478f20c217a672:   2.04 = (0.1, 1.0, 0.8, 0.0, 0.0, 0.1, 0.0)\n",
      "260bbf8c9ca24c63:   1.87 = (0.3, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0)\n",
      "3f1a40fa0636db86:   1.67 = (0.1, 1.0, 0.4, 0.0, 0.0, 0.1, 0.0)\n",
      "bc2adb39c920650d:   2.54 = (0.3, 1.0, 0.7, 0.1, 0.3, 0.3, 0.0)\n",
      "fd01dd625797c4f4:   1.77 = (0.2, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0)\n",
      "2d761afd8c25c25e:   2.16 = (0.1, 1.0, 0.5, 0.0, 0.2, 0.3, 0.0)\n",
      "f3776839f137b8fd:   2.44 = (0.6, 1.0, 0.6, 0.0, 0.0, 0.2, 0.0)\n",
      "c2577510f436a286:   1.83 = (0.3, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0)\n",
      "0669e7730d2cacb6:   1.66 = (0.1, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0)\n",
      "67179a5165a72056:   2.45 = (0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0)\n",
      "13af1122b942a674:   2.25 = (0.2, 1.0, 1.0, 0.0, 0.0, 0.1, 0.0)\n",
      "freesaudiawomen :   2.79 = (0.5, 1.0, 0.4, 0.0, 0.4, 0.5, 0.0)\n",
      "3c536b8d54ca334c:   1.54 = (0.2, 1.0, 0.3, 0.0, 0.1, 0.0, 0.0)\n",
      "aa757d486c6d8bfc:   2.33 = (0.3, 1.0, 0.8, 0.0, 0.0, 0.2, 0.0)\n",
      "ab2adf87b21afa43:   2.51 = (0.1, 0.3, 1.0, 0.2, 0.4, 0.5, 0.0)\n",
      "0a00d0bfdd68bf53:   2.57 = (0.6, 1.0, 0.7, 0.0, 0.0, 0.2, 0.0)\n",
      "a3d8eccd0b8b2cec:   2.66 = (0.4, 1.0, 0.8, 0.0, 0.3, 0.2, 0.0)\n",
      "254403684f5a792b:   2.34 = (0.4, 1.0, 0.5, 0.0, 0.2, 0.2, 0.0)\n",
      "458892294534d85a:   1.99 = (0.7, 0.1, 0.4, 0.7, 0.0, 0.1, 0.0)\n",
      "507cb5a10918355e:   2.03 = (0.1, 1.0, 0.6, 0.0, 0.1, 0.2, 0.0)\n",
      "alsaudiatimes   :   2.48 = (0.7, 1.0, 0.2, 0.2, 0.0, 0.3, 0.0)\n",
      "62ae746780e9ca28:   1.98 = (0.1, 1.0, 0.9, 0.0, 0.0, 0.0, 0.0)\n",
      "983a5489354e160d:   2.01 = (0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0)\n",
      "63d2cc18685dcbfc:   1.73 = (0.3, 0.1, 0.5, 0.5, 0.0, 0.3, 0.0)\n",
      "9907036861c8bf7a:   1.95 = (0.0, 1.0, 0.9, 0.0, 0.0, 0.0, 0.0)\n",
      "fa3140e3b9b4af67:   3.20 = (0.6, 1.0, 0.4, 0.0, 0.6, 0.6, 0.0)\n",
      "fb0a534701840fe9:   0.58 = (0.1, 0.1, 0.2, 0.0, 0.0, 0.2, 0.0)\n",
      "993b679ccbda20b5:   0.69 = (0.0, 0.1, 0.4, 0.0, 0.0, 0.2, 0.0)\n",
      "berniecratss    :   1.65 = (0.3, 0.1, 0.2, 0.2, 0.3, 0.6, 0.0)\n",
      "\n",
      "9 users are suspended without having any tweets in the dataset: 299d67846470c44d, caaa14567470b25d, bc8c3d34bddff82e, 1c2bac6ec8313377, 6e395ce51ae771f4, 8b1498b609a3e879, 79b10b6396d4c863, f3d8b36e08acc468, abbffd30f8ae86a5\n",
      "\n",
      "Domains not in the Media Bias/Fact Check db: fanabc.com, snapalumni.or, actblue.com, whatsupic.com, khamenei.ir, sarahabed.com, wapo.st, ourrev.us, veteranstoday.com, unwomen.org, abacusnews.com, armenpress.am, huffp.st, shar.es, youtu.be, iuvmonline.com, activistpost.com, wjla.com, timemasrya.com, ind.pn, www.cdn.ampproject.org, mirataljazeera.org, yemenpress.org, colorofchange.org, fr-online.de, crwd.fr, battleforthenet.com, owl.li, getbook.at, wxch.nl, news.az,, ow.ly, j.mp, easilydomail.com, news5cleveland.com, cbs5az.com, bit.ly, trib.al, ran.org, bzfd.it, nbcnews.to, periscope.tv, statista.com, bet.us, ilhanomar.com, thenewkhalij.news, elclick.news, palinfo.com, elwatannews.com, eremnews.com, hana-daily-news.com, rol.st, hill.cm, ilkha.com, ift.tt, alalam.ir, news.az, norsecorp.co, read.bi, postbug.com, almahawer.com, buff.ly, alyaum.com, wcsh6.com, pscp.tv, reddit.com, wpxi.com, 6abc.cm, aja.me, facebook.com, photocentra.com, alkawthartv.com, detne.ws, ew.com, upflow.co, dld.bz, awdnews.com, amn.st, aynanewsagency.org, aparat.com, robrogers.com, abcn.ws, www.almanar.com.lb, mailchi.mp, imemc.org, redbubble.com, trendcityradio.com, snp.org, tinyurl.com, reut.rs, wp.me, goo.gl, payement.pw, mepanorama.net, slnm.us, dlvr.it, sabq.org, redd.it, tass.ru, al-saudia.net, malayalamsearch.com, herb.co, pnn.ps, theantimedia.org, power-technology.com, ptv.io, amzn.to, alwaght.com, twitter.com, ti.me, venturebeat.com, elcohetealaluna.com, akhbarak.net, bbc.in, aleqt.com, watanserb.com, alwaienews.net, johnjamessite.com, syriaalhadath.com, rpfront.com, usat.ly, emaratalyoum.com, globalresearch.ca, thesydney.news, danny.vot, alnaharegypt.com, www.alquds.co.uk, democracynow.or, cnn.it, hournews.net, icsft.net, 9nl.at, libertyfrontpress.com, gulf-times.com, topklik.ml, elephantlivesmatter.or, al-hadath24.com, yemenextra.net, 53eig.ht, truthout.org, thepicta.com, scw-services.com, wordpress.com, newsbtc.com, altervista.org, addiyar.com, copts-united.com, amazon.com, bit.do, leopardlegend.com, thedubdeedubrevue.co, gop.cm, instagram.com, bellasbigadventure.co, elmetropolitanoqroo.com, rand.org,, toonsmag.com, soundcloud.com, aml.ink, www.alwatan.com.sa, www.dailystar.com.lb, thesaudireality.com, tamasha.com, nthnews.net, institutomanquehue.org, shopnet.one, children.internationa, misspeachy.co, www.compelling.org.uk, mjhosts.com, aynanewsagency.or, usjournal.us, khabaragency.net, adbl.co, co.uk, trib.in, ln.is, ahtribune.com, farsnews.com, 21stcenturywire.com, conta.cc, str.sg, iuvmpress.com, chuffed.org, www.noticias.yahoo.com, slate.me, un.org, google.com, daysofpalestine.com, middleeasteye.net, bild.de, jordan-times.com, sptnkne.ws, youtube.com, institutomanquehue.org,, fxn.ws, racingtips.com, cgvector.com, arabi21.com, mshrgh.ir, thr.cm, aje.io, jamieoliver.com, run-mizumushi-kun.com, www.rsph.org.uk, howsecureismypassword.net, theiranproject.com, huffpostarabi.com, nwk.ee, hourriya-tagheer.org, nejatngo.org, mehrnews.com, twimg.com, theeconomiccollapseblog.com, bet.com, 9gag.com, atfp.co, callapp.com, wef.ch, business-standard.com, www.haaretz.co.il, gocomics.com, nydn.us, liberalresistance.net, b2blistings.org, ddnnews.com, lualuatv.com, po.st, thepeninsulaqatar.com, www.newsghana.com.gh, travelandleisure.com, snpy.tv, www.okaz.com.sa, mashreghnews.ir, nyt.com, betbitcoin.pr, importedfun.co, maannews.com, mypartnertest.com, dci-palestine.or, prochoiceamerica.org, nyti.ms, balkanspost.com, allrohingyanow.or, coachmikemacdonald.com, huff.to, reddit.co, t.me, dpo.st, granma.cu, nolalikes.com, www.theregister.co.uk, ciudadccs.info, twibbon.com, cpix.me, vogue.com, usjournal.net, favogram.com, ilhanomar.co, mersadnews.net, fb.me, muslimpress.com, techspot.com, anonsworldwide.com, apne.ws, abna.cc, alhadathps.com, gothamist.com, documentinterdit.com\n",
      "\n",
      "Overall factuality of the links in the tweets:{'HIGH': 143, 'MIXED': 141, '': 95, 'VERY HIGH': 9}\n"
     ]
    }
   ],
   "source": [
    "not_in_sources = set([])\n",
    "dataset_sources_factuality = {}\n",
    "\n",
    "\n",
    "users_with_no_tweet = set([])\n",
    "max_account_age = None\n",
    "min_account_age = None\n",
    "\n",
    "print('''Score Dimensions:\n",
    "    creation? account age?,\n",
    "    language_score,\n",
    "    working_time_score,\n",
    "    linked_to_domains_score,\n",
    "    repetition_among_self_tweets,\n",
    "    repetition_among_all_tweets,\n",
    "    has_burst,\n",
    "''')\n",
    "\n",
    "user_counter = 0\n",
    "for screen_name, profile in users.items():\n",
    "    n = len(profile['tweets'])\n",
    "\n",
    "    interface_language = profile['row'][9].lower()[:2]\n",
    "    timezone = profile['row'][9].lower()[:2]\n",
    "    account_age = (DATASET_DATE - datetime.strptime(profile['row'][8], '%Y-%m-%d')).days\n",
    "    if not max_account_age or max_account_age < account_age:\n",
    "        max_account_age = account_age\n",
    "    if not min_account_age or min_account_age > account_age:\n",
    "        min_account_age = account_age\n",
    "    reported_location = profile['row'][3]\n",
    "    if reported_location:\n",
    "        reported_location = reported_location.split(',')[-1].strip()\n",
    "        country = get_country(reported_location)\n",
    "\n",
    "    if n == 0:\n",
    "        users_with_no_tweet.add(screen_name)\n",
    "        profile['scores'] = None\n",
    "        continue\n",
    "\n",
    "    language_score_unmatched = 0\n",
    "    tweet_time_bin = [0] * 24\n",
    "    linked_to_not_factual_domain = 0\n",
    "    linked_to_known_domain = 0\n",
    "    has_burst = False\n",
    "    last_tweet_timestamp = None\n",
    "    for tweet in profile['tweets']:\n",
    "        if tweet[11][:2].lower() != interface_language:\n",
    "            language_score_unmatched += 1\n",
    "\n",
    "        if tweet[13] == last_tweet_timestamp:\n",
    "            has_burst = True\n",
    "\n",
    "        tweet_time = datetime.strptime(tweet[13], '%Y-%m-%d %H:%M')\n",
    "        tweet_time_bin[tweet_time.hour] += 1\n",
    "\n",
    "        urls = tweet[-3][2:-2].split()\n",
    "        for url in urls:\n",
    "            domain = urlparse(url).netloc.lower()\n",
    "            if domain not in sources and domain.count('.') > 1:\n",
    "                domain = domain[domain.index('.')+1:]\n",
    "            if domain not in sources and domain in DOMAIN_ALIASES:\n",
    "                domain = DOMAIN_ALIASES[domain]\n",
    "            if domain not in sources and domain.count('.') > 1:\n",
    "                domain = 'www.' + domain\n",
    "            if domain not in sources:\n",
    "                not_in_sources.add(domain)\n",
    "                continue\n",
    "            linked_to_known_domain += 1\n",
    "            factual = sources[domain][0]['factual']\n",
    "            if factual not in dataset_sources_factuality:\n",
    "                dataset_sources_factuality[factual] = 1\n",
    "            else:\n",
    "                dataset_sources_factuality[factual] += 1\n",
    "            if factual in FACTUAL_HALF:\n",
    "                linked_to_not_factual_domain += 0.5\n",
    "            elif factual not in FACTUAL_COMPLETELY:\n",
    "                linked_to_not_factual_domain += 1\n",
    "\n",
    "    max_sliding_time_window = 0\n",
    "    max_sliding_time_window_sum = 0\n",
    "    for i in range(24):\n",
    "        sliding_time_window_sum = sum(tweet_time_bin[i:(i+8) % 24])\n",
    "        if sliding_time_window_sum > max_sliding_time_window_sum:\n",
    "            max_sliding_time_window_sum = sliding_time_window_sum\n",
    "            max_sliding_time_window = i\n",
    "\n",
    "    # Normalization\n",
    "    language_score = language_score_unmatched / n\n",
    "    working_time_score = ((max_sliding_time_window_sum / n) - (1/3)) * 3 / 2\n",
    "    if linked_to_known_domain > 0:\n",
    "        linked_to_domains_score = linked_to_not_factual_domain / linked_to_known_domain\n",
    "    else:\n",
    "        linked_to_domains_score = 0\n",
    "    repetition_among_self_tweets_score = 0\n",
    "    if screen_name in repeaters_among_self_tweets:\n",
    "        repetition_among_self_tweets_score = log10(repeaters_among_self_tweets[screen_name]) / repeaters_among_self_tweets_max\n",
    "    repetition_among_all_tweets_score = 0\n",
    "    if screen_name in repeaters_among_all_tweets:\n",
    "        repetition_among_all_tweets_score = log10(repeaters_among_all_tweets[screen_name]) / repeaters_among_all_tweets_max\n",
    "\n",
    "    profile['scores'] = [\n",
    "        account_age,  # Will be normalized outside this loop\n",
    "        language_score,\n",
    "        working_time_score,\n",
    "        linked_to_domains_score,\n",
    "        repetition_among_self_tweets_score,\n",
    "        repetition_among_all_tweets_score,\n",
    "        1 if has_burst else 0,\n",
    "    ]\n",
    "\n",
    "    last_tweet_timestamp = tweet[13]\n",
    "\n",
    "    if user_counter == 32:\n",
    "        break\n",
    "    user_counter += 1\n",
    "\n",
    "user_counter = 0\n",
    "for screen_name, profile in users.items():\n",
    "    if profile['scores']:\n",
    "        if max_account_age and min_account_age and max_account_age > min_account_age:\n",
    "            profile['scores'][0] = (profile['scores'][0] - min_account_age) / (max_account_age - min_account_age)\n",
    "\n",
    "        score = sum(profile['scores'])\n",
    "        print('{name:16}: {score:6.2f} = ({vector})'.format(\n",
    "            name=screen_name[:16], score=score, vector=', '.join(['{0:3.1f}'.format(v) for v in profile['scores']])))\n",
    "\n",
    "        if user_counter == 32:\n",
    "            break\n",
    "        user_counter += 1\n",
    "    \n",
    "print()\n",
    "print(\"{num} users are suspended without having any tweets in the dataset: {list}\".format(\n",
    "    num=len(users_with_no_tweet), list=', '.join([s[:16] for s in users_with_no_tweet])))\n",
    "print()\n",
    "print(\"Domains not in the Media Bias/Fact Check db: \" + ', '.join(list(not_in_sources)))\n",
    "print()\n",
    "print(\"Overall factuality of the links in the tweets:\" + str(dataset_sources_factuality))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 users in cluser 0:\n",
      "57e2082d64baa89d: 0.3 1.0 0.5 0.0 0.0 0.1 0.0\n",
      "28478f20c217a672: 0.1 1.0 0.8 0.0 0.0 0.1 0.0\n",
      "260bbf8c9ca24c63: 0.3 1.0 0.6 0.0 0.0 0.0 0.0\n",
      "3f1a40fa0636db86: 0.1 1.0 0.4 0.0 0.0 0.1 0.0\n",
      "bc2adb39c920650d: 0.3 1.0 0.7 0.1 0.3 0.3 0.0\n",
      "fd01dd625797c4f4: 0.2 1.0 0.6 0.0 0.0 0.0 0.0\n",
      "2d761afd8c25c25e: 0.1 1.0 0.5 0.0 0.2 0.3 0.0\n",
      "f3776839f137b8fd: 0.6 1.0 0.6 0.0 0.0 0.2 0.0\n",
      "c2577510f436a286: 0.3 1.0 0.6 0.0 0.0 0.0 0.0\n",
      "0669e7730d2cacb6: 0.1 1.0 0.6 0.0 0.0 0.0 0.0\n",
      "67179a5165a72056: 0.4 1.0 1.0 0.0 0.0 0.0 0.0\n",
      "13af1122b942a674: 0.2 1.0 1.0 0.0 0.0 0.1 0.0\n",
      "3c536b8d54ca334c: 0.2 1.0 0.3 0.0 0.1 0.0 0.0\n",
      "aa757d486c6d8bfc: 0.3 1.0 0.8 0.0 0.0 0.2 0.0\n",
      "0a00d0bfdd68bf53: 0.6 1.0 0.7 0.0 0.0 0.2 0.0\n",
      "a3d8eccd0b8b2cec: 0.4 1.0 0.8 0.0 0.3 0.2 0.0\n",
      "254403684f5a792b: 0.4 1.0 0.5 0.0 0.2 0.2 0.0\n",
      "507cb5a10918355e: 0.1 1.0 0.6 0.0 0.1 0.2 0.0\n",
      "62ae746780e9ca28: 0.1 1.0 0.9 0.0 0.0 0.0 0.0\n",
      "983a5489354e160d: 0.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
      "9907036861c8bf7a: 0.0 1.0 0.9 0.0 0.0 0.0 0.0\n",
      "\n",
      "3 users in cluser 2:\n",
      "11891c406c088fdd: 1.0 0.1 1.0 0.0 0.1 0.1 0.0\n",
      "50012d5e4f959a3d: 0.6 0.2 0.5 0.7 0.0 0.1 0.0\n",
      "458892294534d85a: 0.7 0.1 0.4 0.7 0.0 0.1 0.0\n",
      "\n",
      "6 users in cluser 1:\n",
      "5ddbd530097789a4: 0.3 0.2 0.4 0.2 0.1 0.6 0.0\n",
      "ab2adf87b21afa43: 0.1 0.3 1.0 0.2 0.4 0.5 0.0\n",
      "63d2cc18685dcbfc: 0.3 0.1 0.5 0.5 0.0 0.3 0.0\n",
      "fb0a534701840fe9: 0.1 0.1 0.2 0.0 0.0 0.2 0.0\n",
      "993b679ccbda20b5: 0.0 0.1 0.4 0.0 0.0 0.2 0.0\n",
      "berniecratss    : 0.3 0.1 0.2 0.2 0.3 0.6 0.0\n",
      "\n",
      "3 users in cluser 3:\n",
      "freesaudiawomen : 0.5 1.0 0.4 0.0 0.4 0.5 0.0\n",
      "alsaudiatimes   : 0.7 1.0 0.2 0.2 0.0 0.3 0.0\n",
      "fa3140e3b9b4af67: 0.6 1.0 0.4 0.0 0.6 0.6 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "labels = {}\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit([profile['scores'] for profile in users.values() if profile['scores']])\n",
    "for profile in users.values():\n",
    "    if profile['scores']:\n",
    "        label = int(kmeans.predict([profile['scores']]))\n",
    "        if label not in labels:\n",
    "            labels[label] = [profile]\n",
    "        else:\n",
    "            labels[label].append(profile)\n",
    "\n",
    "for label, profiles in labels.items():\n",
    "    print(\"{num} users in cluser {label}:\".format(num=len(profiles), label=label))\n",
    "    print('\\n'.join(['{name:16}: {vector}'.format(name=p['row'][2][:16], vector=' '.join(['{0:3.1f}'.format(v) for v in p['scores']])) for p in profiles]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
